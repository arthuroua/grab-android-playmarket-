import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from pathlib import Path
import os
import re

# –û—Å–Ω–æ–≤–Ω–∞ URL-–∞–¥—Ä–µ—Å–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑ Wayback Machine
base_url = "https://web.archive.org/web/20240907100524/http://android-playmarket.com/"
site_dir = Path("android-playmarket-site")
site_dir.mkdir(exist_ok=True)

def clean_filename(url):
    # –û–±—Ä–æ–±–∫–∞ Wayback URL ‚Äî –∑–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É —á–∞—Å—Ç–∏–Ω—É
    m = re.match(r"https?://web\.archive\.org/web/\d+[a-z_]*?/(https?://.+)", url)
    if m:
        url = m.group(1)

    parsed = urlparse(url)
    filepath = parsed.netloc + parsed.path

    # –ó–∞–º—ñ–Ω—é—î–º–æ –Ω–µ–±–µ–∑–ø–µ—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏
    filepath = re.sub(r"[<>:\"/\\|?*]", "_", filepath)

    if filepath.endswith("_"):  # –Ø–∫—â–æ –∑–∞–ª–∏—à–∏–≤—Å—è –ø—ñ–¥–∫—Ä–µ—Å–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Å–ª–µ—à–∞
        filepath += "index.html"
    elif not os.path.splitext(filepath)[1]:
        filepath += ".html"

    return site_dir / filepath


def download(url):
    try:
        print(f"‚¨á –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {url}")
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        save_path = clean_filename(url)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, "wb") as f:
            f.write(r.content)
    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ {url}: {e}")

def rewrite_links(soup, tag, attr):
    for el in soup.find_all(tag):
        if el.has_attr(attr):
            original = el[attr]
            full = urljoin(base_url, original)
            el[attr] = clean_filename(full).relative_to(site_dir).as_posix()
            download(full)

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ HTML-—Å—Ç–æ—Ä—ñ–Ω–∫—É
try:
    print(f"üåê –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {base_url}")
    res = requests.get(base_url, timeout=20)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")

    # 2. –ü–µ—Ä–µ–ø–∏—Å–∞—Ç–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏
    rewrite_links(soup, "link", "href")
    rewrite_links(soup, "script", "src")
    rewrite_links(soup, "img", "src")

    # 3. –ó–±–µ—Ä–µ–≥—Ç–∏ HTML
    index_path = site_dir / "index.html"
    with open(index_path, "w", encoding="utf-8") as f:
        f.write(str(soup))
    print(f"‚úÖ –°–∞–π—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {index_path.resolve()}")
except Exception as e:
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Å–∞–π—Ç—É: {e}")
