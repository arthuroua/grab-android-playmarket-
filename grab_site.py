import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from pathlib import Path
import os
import re

# –û—Å–Ω–æ–≤–Ω–∞ URL-–∞–¥—Ä–µ—Å–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑ Wayback Machine
base_url = "https://web.archive.org/web/20240907100524/http://android-playmarket.com/"
site_dir = Path("android-playmarket-site")
site_dir.mkdir(exist_ok=True)

def clean_filename(url):
    # –í–∏—Ç—è–≥—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π URL, —è–∫—â–æ —Ü–µ Wayback Machine
    match = re.search(r'/web/\d+(?:[a-z_]*)/(http.*)', url)
    if match:
        url = match.group(1)

    parsed = urlparse(url)
    filepath = parsed.netloc + parsed.path

    # –ó–∞–±–æ—Ä–æ–Ω–µ–Ω—ñ —Å–∏–º–≤–æ–ª–∏ Windows
    filepath = re.sub(r'[<>:"\\|?*]', "_", filepath)
    if filepath.endswith("/"):
        filepath += "index.html"
    return site_dir / filepath

def download(url):
    try:
        print(f"‚¨á –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {url}")
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        save_path = clean_filename(url)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, "wb") as f:
            f.write(r.content)
    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ {url}: {e}")

def rewrite_links(soup, tag, attr):
    for el in soup.find_all(tag):
        if el.has_attr(attr):
            original = el[attr]
            full = urljoin(base_url, original)
            el[attr] = clean_filename(full).relative_to(site_dir).as_posix()
            download(full)

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ HTML-—Å—Ç–æ—Ä—ñ–Ω–∫—É
try:
    print(f"üåê –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {base_url}")
    res = requests.get(base_url, timeout=20)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")

    # 2. –ü–µ—Ä–µ–ø–∏—Å–∞—Ç–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏
    rewrite_links(soup, "link", "href")
    rewrite_links(soup, "script", "src")
    rewrite_links(soup, "img", "src")

    # 3. –ó–±–µ—Ä–µ–≥—Ç–∏ HTML
    index_path = site_dir / "index.html"
    with open(index_path, "w", encoding="utf-8") as f:
        f.write(str(soup))
    print(f"‚úÖ –°–∞–π—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {index_path.resolve()}")
except Exception as e:
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Å–∞–π—Ç—É: {e}")
